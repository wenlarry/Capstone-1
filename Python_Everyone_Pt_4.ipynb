{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Python_Everyone Pt 4.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenlarry/Capstone-1/blob/master/Python_Everyone_Pt_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouOgNUfMDvDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5da9c8e-4d17-4793-b8b3-013af4a47715"
      },
      "source": [
        "# Spidering Twitter using a db\n",
        "\n",
        "# Create a simple spidering program to go thru Twitter accounts n build a db. \n",
        "\n",
        "# For Spidering program - need to store data as we retrieve it\n",
        "\n",
        "# Start by retrieving one person's Twitter friends n their statuses, looping thru the list of friends n adding\n",
        "#  each of the friends to a db. After processing one person's Twitter friends, check db n retrieve one of the \n",
        "#  friends of the friend.\n",
        "# Track how many times, a particular friend is in the db to get a sense of 'popularity'\n",
        "\n",
        "# Db is stored in the file 'spider.sqlite3' that has one table 'Twitter'. Each row in the table has a col for\n",
        "#  the account name, whether retrieved the friends of this account, and how many times the account has been\n",
        "# 'friended'\n",
        "\n",
        "# In the main loop , prompt the user for a Twitter account name or quit. If the user enters a Twitter account,\n",
        "#  retrieve the list of friends n statuses for that user and add each friend to the db. If the friend is already\n",
        "#  in the list, add 1 to the friends field in the row in the db\n",
        "# If user press enter, look in the db for the next Twitter account that have not retrieved, retrieve the friends n\n",
        "#  n statuses for that account, add to the db or update them n increase their friends count\n",
        "# Once we retrieve the list of friends n statuses, loop thru all the user items in the returned JSON n retrieve\n",
        "#  the screen_name for each user. Then use SELECT statement to see if we hv stored this particular screen_name\n",
        "#  in the db n retrieve the friend count(friends) if the record exists.\n",
        "\n",
        "# Once the sursor executes SELECT. retrieve the rows. Do this with a for statement. If retrieving on row(LIMIT 1),\n",
        "#  use fetchone(). fetchone() returns the row as a tuple.Take the first value from the tuple using to get the\n",
        "#  current friend count into the variable count.\n",
        "# If retrieval is successful, use the SQL UPDATE with a WHERE clause to add 1 to the friends column for the row\n",
        "#  that matches the freind's account. (Note: 2 place holders i.e. ??) in the SQL n the 2nd para to the execute()\n",
        "#  is a 2 element tuple that hold the values to be substituted into the SQL in place of the ??.\n",
        "# If the code in the try block fails, it is probably because no record matched the WHERE name = ? clause on the\n",
        "#  SELECT. so in the except block, use the SQL INSERT to add friend's screen_name to the table with an indication\n",
        "#  that we hv no retrieved the screen_name n set the friend count to zero\n",
        "\n",
        "from urllib.request import urlopen\n",
        "import urllib.error\n",
        "#import twurl\n",
        "import json\n",
        "import sqlite3\n",
        "import ssl\n",
        "\n",
        "TWITTER_URL = 'https://api.twitter.com/1.1/friends/list.json'\n",
        "\n",
        "conn = sqlite3.connect('spider.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS Twitter\n",
        "            (name TEXT, retrieved INTEGER, friends INTEGER)''')\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "while True:\n",
        "    acct = input('Enter a Twitter account, or quit: ')\n",
        "    if (acct == 'quit'): break\n",
        "    if (len(acct) < 1):\n",
        "        cur.execute('SELECT name FROM Twitter WHERE retrieved = 0 LIMIT 1')\n",
        "        try:\n",
        "            acct = cur.fetchone()[0]\n",
        "        except:\n",
        "            print('No unretrieved Twitter accounts found')\n",
        "            continue\n",
        "\n",
        "    url = twurl.augment(TWITTER_URL, {'screen_name': acct, 'count': '20'})\n",
        "    print('Retrieving', url)\n",
        "    connection = urlopen(url, context=ctx)\n",
        "    data = connection.read().decode()\n",
        "    headers = dict(connection.getheaders())\n",
        "\n",
        "    print('Remaining', headers['x-rate-limit-remaining'])\n",
        "    js = json.loads(data)\n",
        "    # Debugging\n",
        "    # print json.dumps(js, indent=4)\n",
        "\n",
        "    cur.execute('UPDATE Twitter SET retrieved=1 WHERE name = ?', (acct, ))\n",
        "\n",
        "    countnew = 0\n",
        "    countold = 0\n",
        "    for u in js['users']:\n",
        "        friend = u['screen_name']\n",
        "        print(friend)\n",
        "        cur.execute('SELECT friends FROM Twitter WHERE name = ? LIMIT 1',\n",
        "                    (friend, ))\n",
        "        try:\n",
        "            count = cur.fetchone()[0]\n",
        "            cur.execute('UPDATE Twitter SET friends = ? WHERE name = ?',\n",
        "                        (count+1, friend))\n",
        "            countold = countold + 1\n",
        "        except:\n",
        "            cur.execute('''INSERT INTO Twitter (name, retrieved, friends)\n",
        "                        VALUES (?, 0, 1)''', (friend, ))\n",
        "            countnew = countnew + 1\n",
        "    print('New accounts=', countnew, ' revisited=', countold)\n",
        "    conn.commit()\n",
        "\n",
        "cur.close()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a Twitter account, or quit: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggitDH2XDvDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99d0e979-9a7f-4f62-d19b-3bbf80e419a4"
      },
      "source": [
        "# For the first time we run the program, the db is empty and a db in the file spider.sqlite 3 is created. A table\n",
        "#  'Twitter' is added to the db. Some friends are retrieved and added to the empty db.\n",
        "# Proceed to weite a simple db dumper to look at what is inside 'spided.sqlite2 file'\n",
        "# This program opens the db n selects all the columns of all the rows in the table 'Twitter' then loops thru the\n",
        "#  rows n prints each row.\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('spider.sqlite')\n",
        "cur = conn.cursor()\n",
        "cur.execute('SELECT * FROM Twitter')\n",
        "count = 0\n",
        "for row in cur:\n",
        "    print(row)\n",
        "    count = count + 1\n",
        "print(count, 'rows.')\n",
        "cur.close()\n",
        "\n",
        "# Output will be as follows\n",
        "#('opencontent', 0,1)\n",
        "#(heheiingold', 0,1)\n",
        "\n",
        "# we get one row for each screen_name, that we hv not retrieved the data for that screen_name (shown as zero) n\n",
        "#  everyone has one friend.\n",
        "# Next our db reflects the retrieval of the friends of our first Twitter account. Run the program againn get it\n",
        "#  to retrieve the friends of the next unprocessed account by 'enter' instead of a Twitter account\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 rows.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYvFdF5CDvDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cont'd from above. As we press enter, the following code is executed\n",
        "# Use the SQL Select to retrieve the name of the first (LIMIT 1) user who still has their 'have we retrieved this\n",
        "#  user' value set to zero. Also use fetchone()[0] pattern within try/except block to extract a screen_name from\n",
        "#  the retrieved data or trigger an error message n loop back up.\n",
        "\n",
        "#if (len(acct) < 1):\n",
        "        #cur.execute('SELECT name FROM Twitter WHERE retrieved = 0 LIMIT 1')\n",
        "        #try:\n",
        "            #acct = cur.fetchone()[0]\n",
        "        #except:\n",
        "            #print('No unretrieved Twitter accounts found')\n",
        "            #continue\n",
        "            \n",
        "# If we successfully retrieved an unprocessed screen-name, we retrieve their data as follows:\n",
        "\n",
        " #url = twurl.augment(TWITTER_URL, {'screen_name': acct, 'count': '20'})\n",
        "    #print('Retrieving', url)\n",
        "    #connection = urllib.urlopen(url)\n",
        "    #data = connection.read()\n",
        "    # js = json.loads(data)\n",
        "    \n",
        "    #cur.execute('UPDATE Twitter SET retrieved=1 WHERE name = ?', (acct, ))\n",
        "    \n",
        "# Once the data is successully retrieved, use the UPDATE statement to set the retrieved column to 1 to indicate\n",
        "#  that we hv completed the retrieval of the friends in this account. this prevents retrieving the data over n over.\n",
        "# Run the friend program n press enter twice to retrieve the next unvisited friend's friends then run the dumping\n",
        "#  program\n",
        "\n",
        "# Output:\n",
        "\n",
        "  #('opencontent', 1,1)\n",
        "  #('kthanos', 0,2)\n",
        "  #('LectureTools', 0,1)\n",
        "\n",
        "# Properly recorded that we hv visited 'opencontent'. Also, 'kthaos' already hv 2 followers\n",
        "# Each time we run the program n press enter it will pick the next unvisited account, retireve their friends,\n",
        "#  marked them as retrieved n for each of the friends of the next account wither add them to the database or\n",
        "#  update their friend account if they are already in the db.\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7uFtA8BDvDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic Data Modeling\n",
        "\n",
        "# Power of a relatiional db lies in the creation of multiple tables n link these tables. How to break application\n",
        "#  data into multiple tables n establishing the relationship btw the tables is 'data modeling'\n",
        "\n",
        "# For the spider Twitter spider application, instead of just counting a person's friends, we want to keep a list\n",
        "#  of all the incoming relationships so we could find a list of everyone who is following a particulat account\n",
        "#  We create a new table that tracks pairs of friends. Code below:\n",
        "\n",
        "#CREATE TABLE Pals(from_friend TEXT, to_friend TEXT)\n",
        "\n",
        "# Each time we encounter a person who Ming is followig, we would insert a row.\n",
        "\n",
        "#INSERT INTO Pals(from_friend,to_friend) VALUES ('ming', 'anon')\n",
        "\n",
        "# A string takes up more space than an integer in the computer's memory n takes more processor time to compare n\n",
        "#  sort. If we hv lots of data in the db n links, it is important to scan data quickly. Therefore, store Twitter\n",
        "#  accounts in a table ' People' instead of the previous table 'Twitter'. The 'People' table has an additional\n",
        "#  col to store the numeric key assoicated with the row for the Twitter user. SQLite has a feature that \n",
        "#  automatically adds the key value for any row inserted into a table using a special type of data col\n",
        "#  (INTEGER PRIMARY KEY)\n",
        "\n",
        "#CREATE TABLE People\n",
        "    #(id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)\n",
        "    \n",
        "# No longer maintaining a friend count in each row of the PEOPLE table. INTEGER PRIMARY KEY - type of id col,\n",
        "#  indicating that SQLite to manage this clo n assign a unique numeric key to each row inserted automatically.\n",
        "#  Add the keyword UNIQUE to indicate that we not allow SQLite to insert 2 row with the same value for name\n",
        "\n",
        "# Instead of creating the table 'Pals', create a table 'Follows' with 2 integer col 'from_id' and 'to_id' n\n",
        "#  a constraint on the table that the combination of 'from_id' and 'to_id' must be unique in this table.\n",
        "\n",
        "#CREATE TABLE Follows\n",
        "    #(from_id INTEGER, to_ID INTEGER, UNIQUE(from_id, to_id))\n",
        "    \n",
        "# When UNIQUE clause is added to the table, we r communicating a set of rules that we are getting the db to\n",
        "#  enforce when we insert records. The rules are to avoid mistakes n to simplify coding.\n",
        "# In creating the 'Follows' table, we are modeliing a relationship where one person 'follows' someone else n\n",
        "#  representing it with a pair of numbers indicating that a) the people are connected and b) the direction of \n",
        "#  the realtionship.\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWhiO64cDvDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be574f35-972b-49e3-d6d3-72c1c6a2aae3"
      },
      "source": [
        "# Programming with multiple tables\n",
        "\n",
        "# Twitter spider program using 2 tables, the primary keys n the key references\n",
        "\n",
        "# Create tables with primary keys n constraints\n",
        "# When we hv a logical key for a person (i.e. account name) n we need the id value for the person, depending\n",
        "#  on whether or not the person is already in the People table, we need to 1) look up the person is already in the\n",
        "#  People table n retrieve the id value for the person or 2)add the person to the People table n get the id value\n",
        "#  for the newly added row\n",
        "# Insert the row that captures the 'follows' relationship\n",
        "# Programming with multiple tables\n",
        "\n",
        "import urllib.request, urllib.parse, urllib.error\n",
        "#import twurl\n",
        "import json\n",
        "import sqlite3\n",
        "import ssl\n",
        "\n",
        "TWITTER_URL = 'https://api.twitter.com/1.1/friends/list.json'\n",
        "\n",
        "conn = sqlite3.connect('friends.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS People\n",
        "            (id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)''')\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS Follows\n",
        "            (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id))''')\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "while True:\n",
        "    acct = input('Enter a Twitter account, or quit: ')\n",
        "    if (acct == 'quit'): break\n",
        "    if (len(acct) < 1):\n",
        "        cur.execute('SELECT id, name FROM People WHERE retrieved=0 LIMIT 1')\n",
        "        try:\n",
        "            (id, acct) = cur.fetchone()\n",
        "        except:\n",
        "            print('No unretrieved Twitter accounts found')\n",
        "            continue\n",
        "    else:\n",
        "        cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1',\n",
        "                    (acct, ))\n",
        "        try:\n",
        "            id = cur.fetchone()[0]\n",
        "        except:\n",
        "            cur.execute('''INSERT OR IGNORE INTO People\n",
        "                        (name, retrieved) VALUES (?, 0)''', (acct, ))\n",
        "            conn.commit()\n",
        "            if cur.rowcount != 1:\n",
        "                print('Error inserting account:', acct)\n",
        "                continue\n",
        "            id = cur.lastrowid\n",
        "\n",
        "    url = twurl.augment(TWITTER_URL, {'screen_name': acct, 'count': '100'})\n",
        "    print('Retrieving account', acct)\n",
        "    try:\n",
        "        connection = urllib.request.urlopen(url, context=ctx)\n",
        "    except Exception as err:\n",
        "        print('Failed to Retrieve', err)\n",
        "        break\n",
        "\n",
        "    data = connection.read().decode()\n",
        "    headers = dict(connection.getheaders())\n",
        "\n",
        "    print('Remaining', headers['x-rate-limit-remaining'])\n",
        "\n",
        "    try:\n",
        "        js = json.loads(data)\n",
        "    except:\n",
        "        print('Unable to parse json')\n",
        "        print(data)\n",
        "        break\n",
        "\n",
        "    # Debugging\n",
        "    # print(json.dumps(js, indent=4))\n",
        "\n",
        "    if 'users' not in js:\n",
        "        print('Incorrect JSON received')\n",
        "        print(json.dumps(js, indent=4))\n",
        "        continue\n",
        "\n",
        "    cur.execute('UPDATE People SET retrieved=1 WHERE name = ?', (acct, ))\n",
        "\n",
        "    countnew = 0\n",
        "    countold = 0\n",
        "    for u in js['users']:\n",
        "        friend = u['screen_name']\n",
        "        print(friend)\n",
        "        cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1',\n",
        "                    (friend, ))\n",
        "        try:\n",
        "            friend_id = cur.fetchone()[0]\n",
        "            countold = countold + 1\n",
        "        except:\n",
        "            cur.execute('''INSERT OR IGNORE INTO People (name, retrieved)\n",
        "                        VALUES (?, 0)''', (friend, ))\n",
        "            conn.commit()\n",
        "            if cur.rowcount != 1:\n",
        "                print('Error inserting account:', friend)\n",
        "                continue\n",
        "            friend_id = cur.lastrowid\n",
        "            countnew = countnew + 1\n",
        "        cur.execute('''INSERT OR IGNORE INTO Follows (from_id, to_id)\n",
        "                    VALUES (?, ?)''', (id, friend_id))\n",
        "    print('New accounts=', countnew, ' revisited=', countold)\n",
        "    print('Remaining', headers['x-rate-limit-remaining'])\n",
        "    conn.commit()\n",
        "cur.close()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a Twitter account, or quit: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1uGE2S4DvD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constraints in db tables\n",
        "\n",
        "# When designing table structures, tell db to enforce few rules. Rules help with errors n including incorrect data\n",
        "#  into tables\n",
        "# Indicate that the name col in the People table must be UNIQUE. Indicate that combination of 2 numbers in each row\n",
        "#  of the Follows table be unique. Help with avoiding errors such as adding the same relationship twice.\n",
        "\n",
        "#cur.execute('''CREATE TABLE IF NOT EXISTS People\n",
        "            #(id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)''')\n",
        "#cur.execute('''CREATE TABLE IF NOT EXISTS Follows\n",
        "            #(from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id))''')\n",
        "\n",
        "# Add 'OR IGNORE' clause to INSERT statement to indicate that if this particular INSERT would cause a violation \n",
        "#  of the 'name must be unique' rule, the db system would ignore the INSERT.\n",
        "\n",
        "#cur.execute('''INSERT OR IGNORE INTO People (name, retrieved) \n",
        "   # VALUES (?, 0)''', (friend, ))\n",
        "\n",
        "# Code ensures that we don't add the exact same Follows relationship twice. Again, tell db to ignore INSERT if it\n",
        "#  violates the uniquess constraint specified for the Follows rows\n",
        "\n",
        "#cur.execute('''INSERT OR IGNORE INTO Follows \n",
        "   # (from_id, to_id) VALUES (?, ?)''', (id, friend_id))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPU8ThDSDvD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve and/or insert a record\n",
        "\n",
        "# Prompt the user for a Twitter account, if the account exists, look up its id value. If account does not yet exist\n",
        "#  in the People table, insert the record n get the id value from the inserted row\n",
        "# Code shows the look up of the id for a friend's account when we hv extracted a screen_name from a user node in the\n",
        "#  retrieved Twitter JSON. \n",
        "# Check if the People record exists using a SELECT statement. If SELECT fails, the fetchone()[0] code will fail n\n",
        "#  control will transfer to the except section\n",
        "# If end up in except code, it means that the row is not found, so insert the row. Use 'INSERT OR IGNORE' just to\n",
        "#  avoid errors n then commit(0) to get db to be updated. \n",
        "# 'cur.rowcount' - check how many rows affected. Attempt is to insert a single row, if the number of affected rows\n",
        "#  is more than 1, it is an error\n",
        "# If INSERT is successful, goto 'cur.lastrowid' to find the value the db assigned to the id col in the new row.\n",
        "\n",
        "#friend = u['screen_name']\n",
        "#cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1',\n",
        "    #(friend, ))\n",
        "#try:\n",
        "    #friend_id = cur.fetchone()[0]\n",
        "    #countold = countold + 1\n",
        "#except:\n",
        "    #cur.execute('''INSERT OR IGNORE INTO People (name, retrieved)\n",
        "        #VALUES (?, 0)''', (friend, ))\n",
        "    #conn.commit()\n",
        "    #if cur.rowcount != 1:\n",
        "        #print('Error inserting account:', friend)\n",
        "        #continue\n",
        "    #friend_id = cur.lastrowid\n",
        "    #countnew = countnew + 1\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bke02HhDvD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing the friend relationship\n",
        "\n",
        "# Once the key value for both the Twitter user n the friend in the JSON  are available, just insert the 2 numbers\n",
        "#  into the Follows table\n",
        "\n",
        "# cur.execute('''INSERT OR IGNORE INTO Follows (from_id, to_id) VALUES (?, ?)''', (id, friend_id))\n",
        "\n",
        "# Output: id, name n visited fields in the People table; numbers of both ends in the relationship in the Follows\n",
        "#  table. In the People table, the first 2 people hv been visited. Data in the Follows table indicates that 'drchuck'\n",
        "#  (user 1) is friend to all of the people in the first 2 rows. \n",
        "\n",
        "# People:\n",
        "# (1, 'drchuck', 1)\n",
        "# (2, ming', 0)\n",
        "# Follows:\n",
        "# (1,2)\n",
        "# (1,2)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkohcuXODvD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Three kinds of keys in a db model\n",
        "\n",
        "# logical key - key that the real world use to look up a row, name field is a logical key. It is the screen name\n",
        "#  for the user. Make sense to add a UNIQUE constraint to a logical key.\n",
        "\n",
        "# Primary key - Usually a number automatically assigned by the db. Seraching for the row using the primary key is\n",
        "#  fastest. id field is an excample\n",
        "\n",
        "# foreign key - Usually a number that points to the primary key of an associate row in a different table. eg from_id\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_a1DQfADvEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using JOIN to retrieve data\n",
        "\n",
        "# With data separated into 2 tables, linked together using primary and foreign keys, build a SELECT that resembles\n",
        "#  the data across the tables.\n",
        "# SQL uses the JOIN clause to reconnect these tables. In the JOINT clause, specify the fields that are used to \n",
        "#  reconnect the rows btw the tables\n",
        "\n",
        "# JOIN clause indicates that the fields selected cross both the Follows and People tables. ON clause indicates how the\n",
        "#  2 tables are to be joined. Take the rows from Follows and append the row from People where the field\n",
        "#  from_id in Follows is the same id value in the People table.\n",
        "# Result of JOIN is to create extra-long 'metarows' which hv both the fields from People and the matching fields from\n",
        "#  Follows. Where there is more than one match btw the id field from People and the from_id from People then JOIN\n",
        "#  creates a metarow for rach of the matching pairs of rows, duplicating data as needed\n",
        "\n",
        "# EG:\n",
        "# SELECT * FROM Follows JOIN People\n",
        "#     ON Follows.from_id = People.id WHERE People.id =1\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZa3Ikh0DvEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5eb978e0-4787-48e9-9717-bd6321a31a09"
      },
      "source": [
        "# Following code shows the data in the db after the multi-table Twitter program (above) has been run several times.\n",
        "# In this program - 1)dump out the People and Follows n then dump out a subset in the tables joined together.\n",
        "\n",
        "# Actual Output:\n",
        "# python twjoin.py\n",
        "# People:\n",
        "#(1 'drchuck', 1)\n",
        "#(4 'steve_coppin', 0)\n",
        "# Follows:\n",
        "#(1,2)\n",
        "#(1,5)\n",
        "#Connections for id_2:\n",
        "#(2,1,1,'drchuck',1)\n",
        "#(2,102,102,'SomethinGirl', 0)\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('friends.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute('SELECT * FROM People')\n",
        "count = 0\n",
        "print('People:')\n",
        "for row in cur:\n",
        "    if count < 5: print(row)\n",
        "    count = count + 1\n",
        "print(count, 'rows.')\n",
        "\n",
        "cur.execute('SELECT * FROM Follows')\n",
        "count = 0\n",
        "print('Follows:')\n",
        "for row in cur:\n",
        "    if count < 5: print(row)\n",
        "    count = count + 1\n",
        "print(count, 'rows.')\n",
        "\n",
        "cur.execute('''SELECT * FROM Follows JOIN People\n",
        "            ON Follows.to_id = People.id\n",
        "            WHERE Follows.from_id = 2''')\n",
        "count = 0\n",
        "print('Connections for id=2:')\n",
        "for row in cur:\n",
        "    if count < 5: print(row)\n",
        "    count = count + 1\n",
        "print(count, 'rows.')\n",
        "\n",
        "cur.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "People:\n",
            "0 rows.\n",
            "Follows:\n",
            "0 rows.\n",
            "Connections for id=2:\n",
            "0 rows.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgX1cXLsDvEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Summary\n",
        "\n",
        "# More complicate to write the code to use db to store data than Python dict.\n",
        "# Db useful - 1) when application needs to make small many random updates within a large data set, 2)when data is\n",
        "#             large n cannot fit in a dict n need to look up info repeatedly, or 3)a long-running process that can\n",
        "#             be stopped n restarted n retained the data from one run to another.\n",
        "\n",
        "# Can build a simple db with a single table to suit many applications but most problems require several tables n\n",
        "#  links/relationships btw rows in different tables. When making links btw tables, do thoughtful design n follow the \n",
        "#  rules of db normalization. Model data efficiently so the program run as fast as possible"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVHG8p5mDvEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Debugging\n",
        "\n",
        "# When developing a Python program to connect to an SQLite db will be to run a Python program n check the results\n",
        "#  using the DB Browser fro SQLite. Browser allows a check to see if the program is working\n",
        "# Careful - SQLite keep 2 programs from changing that same data at the same time. Eg. if you open a db in the\n",
        "#  browser n make a change to the db n hv not yet 'save' in the browser, the browser 'locks' the db file n keeps\n",
        "#  any other program from accessing the file. Python cannot access the file if it is locked. Solution is to either\n",
        "#  close the db in the browser b4 attempting to access the db from Python"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wfafpFSDvEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "559b8219-eea6-4892-eafe-1605ee929f83"
      },
      "source": [
        "# Visualizing mail data\n",
        "\n",
        "# Download: www.py43.com/code3/gmane.zip\n",
        "\n",
        "Analyzing an EMAIL Archive from gmane and vizualizing the data\n",
        "using the D3 JavaScript library\n",
        "\n",
        "This is a set of tools that allow you to pull down an archive\n",
        "of a gmane repository using the instructions at:\n",
        "\n",
        "http://gmane.org/export.php\n",
        "\n",
        "In order not to overwhelm the gmane.org server, I have put up \n",
        "my own copy of the messages at: \n",
        "\n",
        "http://mbox.dr-chuck.net/\n",
        "\n",
        "This server will be faster and take a lot of load off the \n",
        "gmane.org server.\n",
        "\n",
        "You should install the SQLite browser to view and modify the databases from:\n",
        "\n",
        "http://sqlitebrowser.org/\n",
        "\n",
        "The first step is to spider the gmane repository.  The base URL \n",
        "is hard-coded in the gmane.py and is hard-coded to the Sakai\n",
        "developer list.  You can spider another repository by changing that\n",
        "base url.   Make sure to delete the content.sqlite file if you \n",
        "switch the base url.  The gmane.py file operates as a spider in \n",
        "that it runs slowly and retrieves one mail message per second so \n",
        "as to avoid getting throttled by gmane.org.   It stores all of\n",
        "its data in a database and can be interrupted and re-started \n",
        "as often as needed.   It may take many hours to pull all the data\n",
        "down.  So you may need to restart several times.\n",
        "\n",
        "To give you a head-start, I have put up 600MB of pre-spidered Sakai \n",
        "email here:\n",
        "\n",
        "https://www.py4e.com/data_space/content.sqlite.zip\n",
        "\n",
        "If you download this, you can \"catch up with the latest\" by\n",
        "running gmane.py.\n",
        "\n",
        "Navigate to the folder where you extracted the gmane.zip\n",
        "\n",
        "Note: Windows has difficulty in displaying UTF-8 characters\n",
        "in the console so for each console window you open, you may need\n",
        "to type the following command before running this code:\n",
        "\n",
        "    chcp 65001\n",
        "\n",
        "http://stackoverflow.com/questions/388490/unicode-characters-in-windows-command-line-how\n",
        "\n",
        "Here is a run of gmane.py getting the last five messages of the\n",
        "sakai developer list:\n",
        "\n",
        "Mac: python3 gmane.py \n",
        "Win: gmane.py \n",
        "\n",
        "How many messages:10\n",
        "http://mbox.dr-chuck.net/sakai.devel/1/2 2662\n",
        "    ggolden@umich.edu 2005-12-08T23:34:30-06:00 call for participation: developers documentation\n",
        "http://mbox.dr-chuck.net/sakai.devel/2/3 2434\n",
        "    csev@umich.edu 2005-12-09T00:58:01-05:00 report from the austin conference:  sakai developers break into song\n",
        "http://mbox.dr-chuck.net/sakai.devel/3/4 3055\n",
        "    kevin.carpenter@rsmart.com 2005-12-09T09:01:49-07:00 cas and sakai 1.5\n",
        "http://mbox.dr-chuck.net/sakai.devel/4/5 11721\n",
        "    michael.feldstein@suny.edu 2005-12-09T09:43:12-05:00 re: lms/vle rants/comments\n",
        "http://mbox.dr-chuck.net/sakai.devel/5/6 9443\n",
        "    john@caret.cam.ac.uk 2005-12-09T13:32:29+00:00 re: lms/vle rants/comments\n",
        "Does not start with From \n",
        "\n",
        "The program scans content.sqlite from 1 up to the first message number not\n",
        "already spidered and starts spidering at that message.  It continues spidering\n",
        "until it has spidered the desired number of messages or it reaches a page\n",
        "that does not appear to be a properly formatted message.\n",
        "\n",
        "Sometimes gmane.org is missing a message.  Perhaps administrators can delete messages\n",
        "or perhaps they get lost - I don't know.   If your spider stops, and it seems it has hit\n",
        "a missing message, go into the SQLite Manager and add a row with the missing id - leave\n",
        "all the other fields blank - and then restart gmane.py.   This will unstick the \n",
        "spidering process and allow it to continue.  These empty messages will be ignored in the next\n",
        "phase of the process.\n",
        "\n",
        "One nice thing is that once you have spidered all of the messages and have them in \n",
        "content.sqlite, you can run gmane.py again to get new messages as they get sent to the\n",
        "list.  gmane.py will quickly scan to the end of the already-spidered pages and check \n",
        "if there are new messages and then quickly retrieve those messages and add them \n",
        "to content.sqlite.\n",
        "\n",
        "The content.sqlite data is pretty raw, with an innefficient data model, and not compressed.\n",
        "This is intentional as it allows you to look at content.sqlite to debug the process.\n",
        "It would be a bad idea to run any queries against this database as they would be \n",
        "slow.\n",
        "\n",
        "The second process is running the program gmodel.py.  gmodel.py reads the rough/raw \n",
        "data from content.sqlite and produces a cleaned-up and well-modeled version of the \n",
        "data in the file index.sqlite.  The file index.sqlite will be much smaller (often 10X\n",
        "smaller) than content.sqlite because it also compresses the header and body text.\n",
        "\n",
        "Each time gmodel.py runs - it completely wipes out and re-builds index.sqlite, allowing\n",
        "you to adjust its parameters and edit the mapping tables in content.sqlite to tweak the \n",
        "data cleaning process.\n",
        "\n",
        "Running gmodel.py works as follows:\n",
        "\n",
        "Mac: python3 gmodel.py\n",
        "Win: gmodel.py\n",
        "\n",
        "Loaded allsenders 1588 and mapping 28 dns mapping 1\n",
        "1 2005-12-08T23:34:30-06:00 ggolden22@mac.com\n",
        "251 2005-12-22T10:03:20-08:00 tpamsler@ucdavis.edu\n",
        "501 2006-01-12T11:17:34-05:00 lance@indiana.edu\n",
        "751 2006-01-24T11:13:28-08:00 vrajgopalan@ucmerced.edu\n",
        "...\n",
        "\n",
        "The gmodel.py program does a number of data cleaing steps\n",
        "\n",
        "Domain names are truncated to two levels for .com, .org, .edu, and .net \n",
        "other domain names are truncated to three levels.  So si.umich.edu becomes\n",
        "umich.edu and caret.cam.ac.uk becomes cam.ac.uk.   Also mail addresses are\n",
        "forced to lower case and some of the @gmane.org address like the following\n",
        "\n",
        "   arwhyte-63aXycvo3TyHXe+LvDLADg@public.gmane.org\n",
        "\n",
        "are converted to the real address whenever there is a matching real email\n",
        "address elsewhere in the message corpus.\n",
        "\n",
        "If you look in the content.sqlite database there are two tables that allow\n",
        "you to map both domain names and individual email addresses that change over \n",
        "the lifetime of the email list.  For example, Steve Githens used the following\n",
        "email addresses over the life of the Sakai developer list:\n",
        "\n",
        "s-githens@northwestern.edu\n",
        "sgithens@cam.ac.uk\n",
        "swgithen@mtu.edu\n",
        "\n",
        "We can add two entries to the Mapping table\n",
        "\n",
        "s-githens@northwestern.edu ->  swgithen@mtu.edu\n",
        "sgithens@cam.ac.uk -> swgithen@mtu.edu\n",
        "\n",
        "And so all the mail messages will be collected under one sender even if \n",
        "they used several email addresses over the lifetime of the mailing list.\n",
        "\n",
        "You can also make similar entries in the DNSMapping table if there are multiple\n",
        "DNS names you want mapped to a single DNS.  In the Sakai data I add the following\n",
        "mapping:\n",
        "\n",
        "iupui.edu -> indiana.edu\n",
        "\n",
        "So all the folks from the various Indiana University campuses are tracked together\n",
        "\n",
        "You can re-run the gmodel.py over and over as you look at the data, and add mappings\n",
        "to make the data cleaner and cleaner.   When you are done, you will have a nicely\n",
        "indexed version of the email in index.sqlite.   This is the file to use to do data\n",
        "analysis.   With this file, data analysis will be really quick.\n",
        "\n",
        "The first, simplest data analysis is to do a \"who does the most\" and \"which \n",
        "organzation does the most\"?  This is done using gbasic.py:\n",
        "\n",
        "Mac: python3 gbasic.py \n",
        "Win: gbasic.py \n",
        "\n",
        "How many to dump? 5\n",
        "Loaded messages= 51330 subjects= 25033 senders= 1584\n",
        "\n",
        "Top 5 Email list participants\n",
        "steve.swinsburg@gmail.com 2657\n",
        "azeckoski@unicon.net 1742\n",
        "ieb@tfd.co.uk 1591\n",
        "csev@umich.edu 1304\n",
        "david.horwitz@uct.ac.za 1184\n",
        "\n",
        "Top 5 Email list organizations\n",
        "gmail.com 7339\n",
        "umich.edu 6243\n",
        "uct.ac.za 2451\n",
        "indiana.edu 2258\n",
        "unicon.net 2055\n",
        "\n",
        "You can look at the data in index.sqlite and if you find a problem, you \n",
        "can update the Mapping table and DNSMapping table in content.sqlite and\n",
        "re-run gmodel.py.\n",
        "\n",
        "There is a simple vizualization of the word frequence in the subject lines\n",
        "in the file gword.py:\n",
        "\n",
        "Mac: python3 gword.py\n",
        "Win: gword.py\n",
        "\n",
        "Range of counts: 33229 129\n",
        "Output written to gword.js\n",
        "\n",
        "This produces the file gword.js which you can visualize using the file \n",
        "gword.htm.\n",
        "\n",
        "A second visualization is in gline.py.  It visualizes email participation by \n",
        "organizations over time.\n",
        "\n",
        "Mac: python3 gline.py \n",
        "Win: gline.py \n",
        "\n",
        "Loaded messages= 51330 subjects= 25033 senders= 1584\n",
        "Top 10 Oranizations\n",
        "['gmail.com', 'umich.edu', 'uct.ac.za', 'indiana.edu', 'unicon.net', 'tfd.co.uk', 'berkeley.edu', 'longsight.com', 'stanford.edu', 'ox.ac.uk']\n",
        "Output written to gline.js\n",
        "\n",
        "Its output is written to gline.js which is visualized using gline.htm.\n",
        "\n",
        "Some URLs for visualization ideas:\n",
        "\n",
        "https://developers.google.com/chart/\n",
        "\n",
        "https://developers.google.com/chart/interactive/docs/gallery/motionchart\n",
        "\n",
        "https://code.google.com/apis/ajax/playground/?type=visualization#motion_chart_time_formats\n",
        "\n",
        "https://developers.google.com/chart/interactive/docs/gallery/annotatedtimeline\n",
        "\n",
        "http://bost.ocks.org/mike/uberdata/\n",
        "\n",
        "http://mbostock.github.io/d3/talk/20111018/calendar.html\n",
        "\n",
        "http://nltk.org/install.html\n",
        "\n",
        "As always - comments welcome.\n",
        "\n",
        "-- Dr. Chuck"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-b3bff69faafa>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    Analyzing an EMAIL Archive from gmane and vizualizing the data\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERrujhcPDvES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "7e842255-2302-430c-b002-eadeb93e9ac8"
      },
      "source": [
        "# gmane.py\n",
        "\n",
        "import sqlite3\n",
        "import time\n",
        "import ssl\n",
        "import urllib.request, urllib.parse, urllib.error\n",
        "from urllib.parse import urljoin\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Not all systems have this so conditionally define parser\n",
        "try:\n",
        "    import dateutil.parser as parser\n",
        "except:\n",
        "    pass\n",
        "\n",
        "def parsemaildate(md) :\n",
        "    # See if we have dateutil\n",
        "    try:\n",
        "        pdate = parser.parse(tdate)\n",
        "        test_at = pdate.isoformat()\n",
        "        return test_at\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Non-dateutil version - we try our best\n",
        "\n",
        "    pieces = md.split()\n",
        "    notz = \" \".join(pieces[:4]).strip()\n",
        "\n",
        "    # Try a bunch of format variations - strptime() is *lame*\n",
        "    dnotz = None\n",
        "    for form in [ '%d %b %Y %H:%M:%S', '%d %b %Y %H:%M:%S',\n",
        "        '%d %b %Y %H:%M', '%d %b %Y %H:%M', '%d %b %y %H:%M:%S',\n",
        "        '%d %b %y %H:%M:%S', '%d %b %y %H:%M', '%d %b %y %H:%M' ] :\n",
        "        try:\n",
        "            dnotz = datetime.strptime(notz, form)\n",
        "            break\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if dnotz is None :\n",
        "        # print 'Bad Date:',md\n",
        "        return None\n",
        "\n",
        "    iso = dnotz.isoformat()\n",
        "\n",
        "    tz = \"+0000\"\n",
        "    try:\n",
        "        tz = pieces[4]\n",
        "        ival = int(tz) # Only want numeric timezone values\n",
        "        if tz == '-0000' : tz = '+0000'\n",
        "        tzh = tz[:3]\n",
        "        tzm = tz[3:]\n",
        "        tz = tzh+\":\"+tzm\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return iso+tz\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "conn = sqlite3.connect('content.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "baseurl = \"http://mbox.dr-chuck.net/sakai.devel/\"\n",
        "\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS Messages\n",
        "    (id INTEGER UNIQUE, email TEXT, sent_at TEXT,\n",
        "     subject TEXT, headers TEXT, body TEXT)''')\n",
        "\n",
        "# Pick up where we left off\n",
        "start = None\n",
        "cur.execute('SELECT max(id) FROM Messages' )\n",
        "try:\n",
        "    row = cur.fetchone()\n",
        "    if row is None :\n",
        "        start = 0\n",
        "    else:\n",
        "        start = row[0]\n",
        "except:\n",
        "    start = 0\n",
        "\n",
        "if start is None : start = 0\n",
        "\n",
        "many = 0\n",
        "count = 0\n",
        "fail = 0\n",
        "while True:\n",
        "    if ( many < 1 ) :\n",
        "        conn.commit()\n",
        "        sval = input('How many messages:')\n",
        "        if ( len(sval) < 1 ) : break\n",
        "        many = int(sval)\n",
        "\n",
        "    start = start + 1\n",
        "    cur.execute('SELECT id FROM Messages WHERE id=?', (start,) )\n",
        "    try:\n",
        "        row = cur.fetchone()\n",
        "        if row is not None : continue\n",
        "    except:\n",
        "        row = None\n",
        "\n",
        "    many = many - 1\n",
        "    url = baseurl + str(start) + '/' + str(start + 1)\n",
        "\n",
        "    text = \"None\"\n",
        "    try:\n",
        "        # Open with a timeout of 30 seconds\n",
        "        document = urllib.request.urlopen(url, None, 30, context=ctx)\n",
        "        text = document.read().decode()\n",
        "        if document.getcode() != 200 :\n",
        "            print(\"Error code=\",document.getcode(), url)\n",
        "            break\n",
        "    except KeyboardInterrupt:\n",
        "        print('')\n",
        "        print('Program interrupted by user...')\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(\"Unable to retrieve or parse page\",url)\n",
        "        print(\"Error\",e)\n",
        "        fail = fail + 1\n",
        "        if fail > 5 : break\n",
        "        continue\n",
        "\n",
        "    print(url,len(text))\n",
        "    count = count + 1\n",
        "\n",
        "    if not text.startswith(\"From \"):\n",
        "        print(text)\n",
        "        print(\"Did not find From \")\n",
        "        fail = fail + 1\n",
        "        if fail > 5 : break\n",
        "        continue\n",
        "\n",
        "    pos = text.find(\"\\n\\n\")\n",
        "    if pos > 0 :\n",
        "        hdr = text[:pos]\n",
        "        body = text[pos+2:]\n",
        "    else:\n",
        "        print(text)\n",
        "        print(\"Could not find break between headers and body\")\n",
        "        fail = fail + 1\n",
        "        if fail > 5 : break\n",
        "        continue\n",
        "\n",
        "    email = None\n",
        "    x = re.findall('\\nFrom: .* <(\\S+@\\S+)>\\n', hdr)\n",
        "    if len(x) == 1 :\n",
        "        email = x[0];\n",
        "        email = email.strip().lower()\n",
        "        email = email.replace(\"<\",\"\")\n",
        "    else:\n",
        "        x = re.findall('\\nFrom: (\\S+@\\S+)\\n', hdr)\n",
        "        if len(x) == 1 :\n",
        "            email = x[0];\n",
        "            email = email.strip().lower()\n",
        "            email = email.replace(\"<\",\"\")\n",
        "\n",
        "    date = None\n",
        "    y = re.findall('\\Date: .*, (.*)\\n', hdr)\n",
        "    if len(y) == 1 :\n",
        "        tdate = y[0]\n",
        "        tdate = tdate[:26]\n",
        "        try:\n",
        "            sent_at = parsemaildate(tdate)\n",
        "        except:\n",
        "            print(text)\n",
        "            print(\"Parse fail\",tdate)\n",
        "            fail = fail + 1\n",
        "            if fail > 5 : break\n",
        "            continue\n",
        "\n",
        "    subject = None\n",
        "    z = re.findall('\\Subject: (.*)\\n', hdr)\n",
        "    if len(z) == 1 : subject = z[0].strip().lower();\n",
        "\n",
        "    # Reset the fail counter\n",
        "    fail = 0\n",
        "    print(\"   \",email,sent_at,subject)\n",
        "    cur.execute('''INSERT OR IGNORE INTO Messages (id, email, sent_at, subject, headers, body)\n",
        "        VALUES ( ?, ?, ?, ?, ?, ? )''', ( start, email, sent_at, subject, hdr, body))\n",
        "    if count % 50 == 0 : conn.commit()\n",
        "    if count % 100 == 0 : time.sleep(1)\n",
        "\n",
        "conn.commit()\n",
        "cur.close()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How many messages:2\n",
            "http://mbox.dr-chuck.net/sakai.devel/21/22 2625\n",
            "    csev@umich.edu 2005-12-12T11:33:29-05:00 sepp library discussion group renamed - now with open membership\n",
            "http://mbox.dr-chuck.net/sakai.devel/22/23 2960\n",
            "    pgoldweic@northwestern.edu 2005-12-12T13:16:12-06:00 problems accessing the collab site with internet explorer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-949530ae6e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mmany\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0msval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'How many messages:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA9TGg7YDvEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "0da2bdd3-9601-4db0-f6dc-daf177b7a241"
      },
      "source": [
        "# gmodel.py\n",
        "\n",
        "import sqlite3\n",
        "import time\n",
        "import ssl\n",
        "import urllib.request, urllib.parse, urllib.error\n",
        "from urllib.parse import urljoin\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Not all systems have this so conditionally define parser\n",
        "try:\n",
        "    import dateutil.parser as parser\n",
        "except:\n",
        "    pass\n",
        "\n",
        "def parsemaildate(md) :\n",
        "    # See if we have dateutil\n",
        "    try:\n",
        "        pdate = parser.parse(tdate)\n",
        "        test_at = pdate.isoformat()\n",
        "        return test_at\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Non-dateutil version - we try our best\n",
        "\n",
        "    pieces = md.split()\n",
        "    notz = \" \".join(pieces[:4]).strip()\n",
        "\n",
        "    # Try a bunch of format variations - strptime() is *lame*\n",
        "    dnotz = None\n",
        "    for form in [ '%d %b %Y %H:%M:%S', '%d %b %Y %H:%M:%S',\n",
        "        '%d %b %Y %H:%M', '%d %b %Y %H:%M', '%d %b %y %H:%M:%S',\n",
        "        '%d %b %y %H:%M:%S', '%d %b %y %H:%M', '%d %b %y %H:%M' ] :\n",
        "        try:\n",
        "            dnotz = datetime.strptime(notz, form)\n",
        "            break\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if dnotz is None :\n",
        "        # print 'Bad Date:',md\n",
        "        return None\n",
        "\n",
        "    iso = dnotz.isoformat()\n",
        "\n",
        "    tz = \"+0000\"\n",
        "    try:\n",
        "        tz = pieces[4]\n",
        "        ival = int(tz) # Only want numeric timezone values\n",
        "        if tz == '-0000' : tz = '+0000'\n",
        "        tzh = tz[:3]\n",
        "        tzm = tz[3:]\n",
        "        tz = tzh+\":\"+tzm\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return iso+tz\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "conn = sqlite3.connect('content.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "baseurl = \"http://mbox.dr-chuck.net/sakai.devel/\"\n",
        "\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS Messages\n",
        "    (id INTEGER UNIQUE, email TEXT, sent_at TEXT,\n",
        "     subject TEXT, headers TEXT, body TEXT)''')\n",
        "\n",
        "# Pick up where we left off\n",
        "start = None\n",
        "cur.execute('SELECT max(id) FROM Messages' )\n",
        "try:\n",
        "    row = cur.fetchone()\n",
        "    if row is None :\n",
        "        start = 0\n",
        "    else:\n",
        "        start = row[0]\n",
        "except:\n",
        "    start = 0\n",
        "\n",
        "if start is None : start = 0\n",
        "\n",
        "many = 0\n",
        "count = 0\n",
        "fail = 0\n",
        "while True:\n",
        "    if ( many < 1 ) :\n",
        "        conn.commit()\n",
        "        sval = input('How many messages:')\n",
        "        if ( len(sval) < 1 ) : break\n",
        "        many = int(sval)\n",
        "\n",
        "    start = start + 1\n",
        "    cur.execute('SELECT id FROM Messages WHERE id=?', (start,) )\n",
        "    try:\n",
        "        row = cur.fetchone()\n",
        "        if row is not None : continue\n",
        "    except:\n",
        "        row = None\n",
        "\n",
        "    many = many - 1\n",
        "    url = baseurl + str(start) + '/' + str(start + 1)\n",
        "\n",
        "    text = \"None\"\n",
        "    try:\n",
        "        # Open with a timeout of 30 seconds\n",
        "        document = urllib.request.urlopen(url, None, 30, context=ctx)\n",
        "        text = document.read().decode()\n",
        "        if document.getcode() != 200 :\n",
        "            print(\"Error code=\",document.getcode(), url)\n",
        "            break\n",
        "    except KeyboardInterrupt:\n",
        "        print('')\n",
        "        print('Program interrupted by user...')\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(\"Unable to retrieve or parse page\",url)\n",
        "        print(\"Error\",e)\n",
        "        fail = fail + 1\n",
        "        if fail > 5 : break\n",
        "        continue\n",
        "\n",
        "    print(url,len(text))\n",
        "    count = count + 1\n",
        "\n",
        "    if not text.startswith(\"From \"):\n",
        "        print(text)\n",
        "        print(\"Did not find From \")\n",
        "        fail = fail + 1\n",
        "        if fail > 5 : break\n",
        "        continue\n",
        "\n",
        "    pos = text.find(\"\\n\\n\")\n",
        "    if pos > 0 :\n",
        "        hdr = text[:pos]\n",
        "        body = text[pos+2:]\n",
        "    else:\n",
        "        print(text)\n",
        "        print(\"Could not find break between headers and body\")\n",
        "        fail = fail + 1\n",
        "        if fail > 5 : break\n",
        "        continue\n",
        "\n",
        "    email = None\n",
        "    x = re.findall('\\nFrom: .* <(\\S+@\\S+)>\\n', hdr)\n",
        "    if len(x) == 1 :\n",
        "        email = x[0];\n",
        "        email = email.strip().lower()\n",
        "        email = email.replace(\"<\",\"\")\n",
        "    else:\n",
        "        x = re.findall('\\nFrom: (\\S+@\\S+)\\n', hdr)\n",
        "        if len(x) == 1 :\n",
        "            email = x[0];\n",
        "            email = email.strip().lower()\n",
        "            email = email.replace(\"<\",\"\")\n",
        "\n",
        "    date = None\n",
        "    y = re.findall('\\Date: .*, (.*)\\n', hdr)\n",
        "    if len(y) == 1 :\n",
        "        tdate = y[0]\n",
        "        tdate = tdate[:26]\n",
        "        try:\n",
        "            sent_at = parsemaildate(tdate)\n",
        "        except:\n",
        "            print(text)\n",
        "            print(\"Parse fail\",tdate)\n",
        "            fail = fail + 1\n",
        "            if fail > 5 : break\n",
        "            continue\n",
        "\n",
        "    subject = None\n",
        "    z = re.findall('\\Subject: (.*)\\n', hdr)\n",
        "    if len(z) == 1 : subject = z[0].strip().lower();\n",
        "\n",
        "    # Reset the fail counter\n",
        "    fail = 0\n",
        "    print(\"   \",email,sent_at,subject)\n",
        "    cur.execute('''INSERT OR IGNORE INTO Messages (id, email, sent_at, subject, headers, body)\n",
        "        VALUES ( ?, ?, ?, ?, ?, ? )''', ( start, email, sent_at, subject, hdr, body))\n",
        "    if count % 50 == 0 : conn.commit()\n",
        "    if count % 100 == 0 : time.sleep(1)\n",
        "\n",
        "conn.commit()\n",
        "cur.close()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://mbox.dr-chuck.net/sakai.devel/23/24 4715\n",
            "    pgoldweic@northwestern.edu 2005-12-12T14:20:41-06:00 re: problems accessing the collab site with internet\n",
            "http://mbox.dr-chuck.net/sakai.devel/24/25 2705\n",
            "    andrew@caret.cam.ac.uk 2005-12-12T14:23:12+00:00 file picker for non-legacy tools\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7a1033e0fa0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mmany\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0msval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'How many messages:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}